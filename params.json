{"name":"Blobs","tagline":"Smart Clustering at the Urban Level","body":"Blobs: Smart Clustering at the Urban Level\r\n=====\r\n\r\n*v0.9: June 2015*\r\n\r\nSpatial analytics is often hampered by the arbitrary choice of units, allowing local heterogeneity to obscure true patterns. Blobs is a new “smart clustering” technique that lets us use large quantities of open municipal data from [Plenario](http://plenar.io) to redraw city maps to reflect facts on the ground, not administrative boundaries. \r\n\r\nThe algorithm, built on the *max-p regions* implementation by researchers at Arizona State University, creates spatial clusters using only one input parameter, the minimum size of each cluster (defined in any of several ways). This nonparametric approach creates clusters that fit the data as closely as possible, fully isolating regions based only on the variables of interest.  \r\n\r\nThis package allows a user to create \"blobs\" from start to finish using any dataset in Plenario. This involves the following:\r\n\r\n* Downloading the relevant data from Plenario, at the desired unit of analysis (currently supports Census blocks and tracts)\r\n* Building blobs from those units of analysis using counts of observations from any combination of the requested datasets\r\n* Map the blobs solution along any variable\r\n* Cluster blobs using k-means\r\n* Save data on blobs to use in any research or administrative solution\r\n\r\nMore information on the basic approach can be found in the [documentation for the PySAL Maxp class](http://www.pysal.org/library/region/maxp.html), upon which blobs is built. \r\n\r\n\r\nDependencies\r\n------------\r\n\r\n* pysal\r\n* numpy\r\n* pandas\r\n* matplotlib.pyplot with mpl_toolkits.mplot3d\r\n* sklearn.cluster\r\n\r\nRepository Structure\r\n------------\r\n\r\n##### Primary\r\n\r\n* `blobs.py` - main module\r\n* `maxp.py` - Updated version of the maxp.py module in pysal/region \r\n* `smoothing.py` - adventures in spatial autocorrelation\r\n\r\n##### Secondary (Samples from Chicago)\r\n\r\n* `blocks/` - Census block shapefiles (Chicago only)\r\n* `tracts/` - Census tract shapefiles (Chicago only)\r\n* `configure.py` - example code for building the shapefiles and associated files using Census data\r\n* `Chicago Census.csv` - Census IDs and population data for blocks in Chicago\r\n* `master311.csv` - sample Plenario data on Chicago 311 calls by Census tract\r\n\r\n  \r\nExample Usage\r\n----------------------\r\n######  Using Chicago data, included\r\n\r\n```python\r\nimport blobs\r\n\r\n############\r\n## tract level\r\n############\r\n\r\n# download the data\r\nd = blobs.Blobs_Data('Chicago Census.csv', 'tract', 'tracts/CensusTractsTIGER2010.shp', \r\n  'tractce10', ['crimes_2001_to_present', \r\n  '311_service_requests_vacant_and_abandoned_building', \r\n  '311_service_requests_rodent_baiting'])\r\n\r\n# create blobs (minimum population of 10,000 in each blob)\r\nb = blobs.Blobs(d, 'pop', 10000)\r\n\r\n# cluster the blobs along similarities in the data\r\ncl = blobs.Cluster_blobs(b.blobs_data, blobs_per_cluster=10)\r\n\r\n# create blobs with a minimum of 30 tracts in each blob, and cluster\r\nb = blobs.Blobs(d, 'areas', 30)\r\ncl = blobs.Cluster_blobs(b, blobs_per_cluster=10)\r\n\r\n# have around 3 blobs per cluster\r\ncl.set_n_clusters(3)\r\n\r\n# see blob assignments\r\nb.assignments\r\n\r\n# see cluster assignments\r\ncl.clusters2blobs\r\n\r\n# plot blobs along one of the variables\r\nb.plot_blobs('crimes_2001_to_present')\r\n\r\n\r\n############\r\n## block level\r\n############\r\n\r\nd = blobs.Blobs_Data('Chicago Census.csv', 'block', 'blocks/CensusBlockTIGER2010.shp', \r\n  'geoid10', ['crimes_2001_to_present', \r\n  '311_service_requests_vacant_and_abandoned_building', \r\n  '311_service_requests_rodent_baiting'])\r\nb = blobs.Blobs(d, 'pop', 10000)\r\ncl = blobs.Cluster_blobs(b, blobs_per_cluster=10)\r\n\r\n\r\n\r\n###########\r\n## instant examples\r\n###########\r\n\r\n# if you don't want to download data now, you can test out blobs using some included data\r\n# just run the following\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport pysal as ps\r\nshp_link = 'tracts/CensusTractsTIGER2010.shp'\r\ndbf = ps.open('tracts/CensusTractsTIGER2010.dbf')\r\ncols = np.array([dbf.by_col(col) for col in dbf.header]).T\r\ndf = pd.DataFrame(cols)\r\ndf.columns = dbf.header\r\ndf.columns = df.columns.map(lambda x: x.lower())\r\ndf.commarea = df.commarea.astype('int')\r\ndf['order'] = df.index\r\nw=ps.open('tracts/CensusTractsTIGER2010.gal').read()\r\ninit_calls = pd.read_csv('master311.csv', dtype=object)\r\nfor c in init_calls.columns[1:]:\r\n    init_calls[c] = init_calls[c].astype('float')\r\n\r\n# format data and merge on shapefile IDs\r\nordered_tracts = pd.DataFrame(df.loc[:,['tractce10', 'commarea', 'order']])\r\ncalls = pd.merge(init_calls, ordered_tracts, how='right', left_on='tractID', \r\n    right_on='tractce10', sort=False).fillna(0).sort(['order'])\r\ncalls = calls.drop(['order', 'commarea'],1)\r\n\r\nclass bd:\r\n  data = calls\r\n  w = w\r\n  shp_link = shp_link\r\n  id = 'tractce10'\r\n  level = 'tract'\r\n\r\nd = bd()\r\nb = blobs.Blobs(d, 'pop', 10000, iterations=1)\r\ncl = blobs.Cluster_blobs(b, blobs_per_cluster=10)\r\n\r\n\r\n```\r\n\r\n\r\n\r\n","google":"UA-64325541-1","note":"Don't delete this file! It's used internally to help with page regeneration."}